{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook of all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datamanagement\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import datetime\n",
    "import copy\n",
    "\n",
    "# import models\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# import evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# import visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv(\"../NOTEBOOKS TO REVIEW/Job/dataset_cyb&non_v2.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = copy.deepcopy(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def now():\n",
    "    now = datetime.datetime.now()   \n",
    "    return now.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model(train,test,train_labels,test_labels):\n",
    "    #train model\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    clf.fit(train, train_labels)\n",
    "    \n",
    "    #test model\n",
    "    y_pred = clf.predict(test)\n",
    "    score = classification_report(y_pred, test_labels, output_dict=True)\n",
    "    df_score = pd.DataFrame(score).transpose()\n",
    "    df_score.to_csv('svm_score_run_'+now()+'.csv', sep=\";\", index=False)\n",
    "    \n",
    "    #saving TP\n",
    "    SVMTest = test.copy()\n",
    "    SVMTest['Predicted'] = y_pred\n",
    "    SVMTest['Actual'] = test_labels\n",
    "    SVMTest = SVMTest.loc[SVMTest['Predicted'] == SVMTest['Actual']]\n",
    "    SVM_Predictions = data.iloc[list(SVMTest.index.values.tolist())]\n",
    "    SVM_Predictions.to_csv('svm_TP_run_'+now()+'.csv', sep=\";\", index=False)\n",
    "      \n",
    "    #postitive target feature importance\n",
    "    svm_feature_result = pd.DataFrame({'feature': train.columns,'importance': clf.coef_[0]}).sort_values('importance', ascending = False)\n",
    "    svm_feature_result.to_csv('svm_featureimp_run_'+now()+'.csv', sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_model(train,test,train_labels,test_labels):\n",
    "    #train model\n",
    "    model = RandomForestClassifier(n_estimators=29, max_features = 0.7999999999999999, n_jobs=-1, verbose = 1, max_depth = 10, bootstrap = True)\n",
    "    model.fit(train, train_labels)\n",
    "   \n",
    "    #test model\n",
    "    rf_predictions = model.predict(test)\n",
    "    score = classification_report(rf_predictions, test_labels, output_dict=True)\n",
    "    df_score = pd.DataFrame(score).transpose()\n",
    "    df_score.to_csv('rf_score_run_'+now()+'.csv', sep=\";\", index=False)\n",
    "    \n",
    "    #saving TP\n",
    "    RFTest = test.copy()\n",
    "    RFTest['Predicted'] = rf_predictions\n",
    "    RFTest['Actual'] = test_labels\n",
    "    RFTest = RFTest.loc[RFTest['Predicted'] == RFTest['Actual']]\n",
    "    RF_Predictions = data.iloc[list(RFTest.index.values.tolist())]\n",
    "    RF_Predictions.to_csv('rf_TP_run_'+now()+'.csv', sep=\";\", index=False)\n",
    "\n",
    "    #postitive target feature importance\n",
    "    rf_feature_result = pd.DataFrame({'feature': train.columns,'importance': model.feature_importances_}).sort_values('importance', ascending = False)\n",
    "    rf_feature_result.to_csv('rf_featureimp_run_'+now()+'.csv', sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree with Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtgb_model(train,test,train_labels,test_labels):\n",
    "    #train model\n",
    "    model = GradientBoostingClassifier(n_estimators=100, max_depth=4, subsample=0.99, learning_rate=0.977)\n",
    "    model.fit(train, train_labels)\n",
    "    \n",
    "    #test model\n",
    "    dtgb_predictions = model.predict(test)\n",
    "    score = classification_report(dtgb_predictions, test_labels, output_dict=True)\n",
    "    df_score = pd.DataFrame(score).transpose()\n",
    "    df_score.to_csv('/Job/run/dtgb_score_run_'+now()+'.csv', sep=\";\", index=False)\n",
    "    \n",
    "    #saving TP\n",
    "    DTGBTest = test.copy()\n",
    "    DTGBTest['Predicted'] = dtgb_predictions\n",
    "    DTGBTest['Actual'] = test_labels\n",
    "    DTGBTest = DTGBTest.loc[DTGBTest['Predicted'] == DTGBTest['Actual']]\n",
    "    DTGB_Predictions = data.iloc[list(DTGBTest.index.values.tolist())]\n",
    "    DTGB_Predictions.to_csv('/run/dtgb_final_TP_run_'+now()+'.csv', sep=\";\", index=False)\n",
    "\n",
    "    #postitive target feature importance\n",
    "    dtgb_feature_result = pd.DataFrame({'feature': train.columns,'importance': model.feature_importances_}).sort_values('importance', ascending = False)\n",
    "    dtgb_feature_result.to_csv('/run/dtgb_featureimp_run_'+now()+'.csv', sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_model(train,test,train_labels,test_labels):\n",
    "    #train model\n",
    "    logmodel = LogisticRegression(solver = 'lbfgs')\n",
    "    logmodel.fit(train, train_labels)\n",
    "    \n",
    "    #test model\n",
    "    predictions = logmodel.predict(test)\n",
    "    score = classification_report(predictions, test_labels, output_dict=True)\n",
    "    df_score = pd.DataFrame(score).transpose()    \n",
    "    df_score.to_csv('/run/logreg_score_run_'+now()+'.csv', sep=\";\", index=False)\n",
    "    \n",
    "    #saving TP\n",
    "    LRTest = test.copy()\n",
    "    LRTest['Predicted'] = predictions\n",
    "    LRTest['Actual'] = test_labels\n",
    "    LRTest = LRTest.loc[LRTest['Predicted'] == LRTest['Actual']]\n",
    "    LR_Predictions = data.iloc[list(LRTest.index.values.tolist())]\n",
    "    LR_Predictions.to_csv('/run/logreg_final_TP_run_'+now()+'.csv', sep=\";\", index=False)\n",
    "    \n",
    "    #postive target feature importance\n",
    "    logreg_feature_result = pd.DataFrame({'feature': train.columns,'importance': logmodel.coef_[0]}).sort_values('importance', ascending = False)\n",
    "    logreg_feature_result.to_csv('/run/logreg_featureimp_run_'+now()+'.csv', sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non = df_copy.loc[df_copy['is_cyber_victim_1'] == 0]\n",
    "df_cyber = df_copy.loc[df_copy['is_cyber_victim_1'] == 1]\n",
    "sample_size = len(df_cyber)\n",
    "loop_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running model mulitple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(loop_size):\n",
    "    #sampling data\n",
    "    data = pd.read_csv(\"stratified_TP_data_2020-01-14 19:06:54.csv\", sep=';')\n",
    "    \n",
    "    #splitting data\n",
    "    labels = np.array(data.pop('is_cyber_victim_1'))\n",
    "    train, test, train_labels, test_labels = train_test_split(data, labels, stratify = labels, test_size = 0.3, random_state = 21)\n",
    "    \n",
    "    #running models\n",
    "    dtgb_model(train, test, train_labels, test_labels)\n",
    "    logreg_model(train, test, train_labels, test_labels)\n",
    "    rf_model(train, test, train_labels, test_labels)   \n",
    "    svm_model(train, test, train_labels, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
